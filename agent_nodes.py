# agent_nodes.py

import os, re, textwrap, subprocess, json, time
from typing import List, Dict, Optional, TypedDict, Any
from openai import OpenAI
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE, PP_PLACEHOLDER

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from utils import clean_text, split_sents, ffprobe_duration, img_to_data_url, render_mp4, concat_videos_ffmpeg, export_slide_as_png

# --- í™˜ê²½ ì„¤ì • ---
LLM_MODEL = "gpt-4o-mini"
TTS_MODEL = "tts-1" # TTS-1-HDê°€ ë” ê³ ìŒì§ˆì´ë‚˜, tts-1ì´ ë” ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì 
client = OpenAI()

# --- State ì •ì˜ ---
class State(TypedDict, total=False):
  pptx_path: str
  work_dir: str
  prompt: Dict
  slide_index: int
  total_slides: int # ì¶”ê°€: ì´ ìŠ¬ë¼ì´ë“œ ìˆ˜

  titles: List[str]
  texts: List[str]
  tables: List[List[List[str]]]
  images: List[str]
  shape_texts: List[str] # ë„í˜• í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  í•„ë“œ ì¶”ê°€
  slide_image: List[str]
  
  external_content: Dict[str, List[Dict[str, str]]]

  page_content: str
  script: str
  all_scripts: List[str] # ëˆ„ì  ìŠ¤í¬ë¦½íŠ¸
  quiz_set: List[Dict[str, Any]]
  
  audio: str
  video_path: List[str]
  video_paths: List[str]
  final_video: str
  
  failed_slides: List[int] # ì‹¤íŒ¨í•œ ìŠ¬ë¼ì´ë“œ ì¸ë±ìŠ¤ ì €ì¥

# ===============================
# ğŸ”¹ Node Functions
# ===============================

def get_shapes_text(shape):
    """í•˜ë‚˜ì˜ ë„í˜•(ë˜ëŠ” ê·¸ë£¹)ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ"""
    texts = []
    if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
        for sh in shape.shapes:
            texts.extend(get_shapes_text(sh))
    elif shape.shape_type == MSO_SHAPE_TYPE.AUTO_SHAPE and shape.has_text_frame:
        text = shape.text.strip()
        if text:
            texts.append(text)
    return texts

def node_parse_all(state: State) -> State:
    """PPT íŒŒì¼ì—ì„œ ëª¨ë“  ìŠ¬ë¼ì´ë“œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì´ë¯¸ì§€ë¡œ ë³€í™˜ (1íšŒ ì‹¤í–‰)"""
    
    ppt = Presentation(state['pptx_path'])
    work_dir = state.get("work_dir", "./")

    # ë¯¸ë””ì–´/ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ì„¤ì •
    MEDIA_DIR = os.path.join(work_dir, "media")
    SLIDES_DIR = os.path.join(work_dir, "slides")
    os.makedirs(MEDIA_DIR, exist_ok=True)
    os.makedirs(SLIDES_DIR, exist_ok=True)

    texts, tables, images, titles, slide_image, shapes = [], [], [], [], [], []

    for slide_idx, slide in enumerate(ppt.slides):
        # 1. ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€(ìŠ¤ëƒ…ìƒ·) ì¶”ì¶œ
        slide_state = {"pptx_path": state['pptx_path'], "work_dir": SLIDES_DIR, "slide_index": slide_idx}
        slide_state = export_slide_as_png(slide_state)
        
        src_path = slide_state["slide_image"]
        dst_path = os.path.join(SLIDES_DIR, f"slide_img{slide_idx+1}.png")
        if os.path.exists(src_path):
            os.replace(src_path, dst_path) # íŒŒì¼ ì´ë™
            slide_image.append(dst_path)
        else:
            slide_image.append(None)

        # 2. í…ìŠ¤íŠ¸, í‘œ, ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
        full_slide_text, slide_tables, slide_images, slide_title, slide_shapes_texts = "", [], [], "", []
        
        for sh in slide.shapes:
            if sh.is_placeholder and sh.placeholder_format.type == PP_PLACEHOLDER.TITLE and sh.has_text_frame:
                slide_title = sh.text.strip()

            if sh.has_text_frame:
                full_slide_text += "\\n".join(p.text for p in sh.text_frame.paragraphs) + "\\n"
            
            if sh.shape_type == MSO_SHAPE_TYPE.TABLE:
                tbl = [[clean_text(c.text) for c in r.cells] for r in sh.table.rows]
                slide_tables.append(tbl)
            
            # ë„í˜• í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì¬ê·€)
            slide_shapes_texts.extend(get_shapes_text(sh))

            if sh.shape_type == MSO_SHAPE_TYPE.PICTURE:
                ext = sh.image.ext
                img_filename = f"slide{slide_idx+1}_img_{len(slide_images)}.{ext}"
                path = os.path.join(MEDIA_DIR, img_filename)
                slide_images.append(path)
                with open(path, "wb") as f:
                    f.write(sh.image.blob)

        # 3. ê²°ê³¼ ëˆ„ì 
        texts.append(clean_text(full_slide_text))
        tables.append(slide_tables)
        images.append(slide_images)
        titles.append(slide_title)
        shapes.append(",".join(slide_shapes_texts))

    # 4. State ì €ì¥
    state.update({
        'texts': texts,
        'tables': tables,
        'images': images,
        'slide_image': slide_image,
        'titles': titles,
        'shape_texts': shapes,
        "total_slides": len(ppt.slides)
    })
    
    return state

def serpapi_search_by_title(title: str, num: int = 4) -> list[dict]:
    """SerpAPIë¥¼ ì´ìš©í•´ ì‹¤ì œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë°˜í™˜"""
    key = os.getenv("SERPAPI_API_KEY")
    EXCLUDE_DOMAINS = ["blog.naver.com", "tistory.com", "brunch.co.kr", "medium.com", "velog.io", "kin.naver.com", "reddit.com", "youtube.com"]
    query = f"{title} " + " ".join([f"-site:{d}" for d in EXCLUDE_DOMAINS])
    
    try:
        res = requests.get("https://serpapi.com/search.json", params={
            "engine": "google", "q": query, "hl": "ko", "gl": "kr", "num": num, "api_key": key
        }, timeout=15)
        
        data = res.json().get("organic_results", []) or []
        results = []
        for item in data:
            url = item.get("link", "")
            if not url: continue
            domain = urlparse(url).netloc
            results.append({
                "title": item.get("title", ""),
                "url": url,
                "snippet": item.get("snippet", ""),
                "domain": domain
            })
        return results
    except Exception as e:
        print(f"[SerpAPI ì˜¤ë¥˜] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def node_tool_search(state: dict) -> dict:
    """ì™¸ë¶€ ê²€ìƒ‰ ë…¸ë“œ: ìŠ¬ë¼ì´ë“œ ì œëª©ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ stateì— ì €ì¥"""
    idx = state.get("slide_index", 0)
    titles = state.get("titles", [])
    texts_all = state.get("texts", [])
    tables_all = state.get("tables", [])
    images_all = state.get("images", [])

    title = titles[idx] if idx < len(titles) else ""
    texts = texts_all[idx] if idx < len(texts_all) else ""
    
    state["external_content"] = {"queries": [], "summaries": [], "references": []} # ì´ˆê¸°í™”

    # ì¿¼ë¦¬ ìƒì„± ë¡œì§ (ìƒëµ: ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    queries = []
    if title: queries.append({"text": title, "context": "title"})
    if title and texts: queries.append({"text": f"{title} {texts[:80]}", "context": "title+text"})
    # ... (í•„ìš”ì— ë”°ë¼ table, image ì¿¼ë¦¬ ì¶”ê°€ ë¡œì§)
    
    # ê²€ìƒ‰ ìˆ˜í–‰
    all_results = []
    for q in queries:
        results = serpapi_search_by_title(q["text"], num=4)
        all_results.extend(results)
        time.sleep(0.2)
        
    # ê²°ê³¼ ì •ë¦¬ (ì¤‘ë³µ ì œê±° ë° êµ¬ì¡°í™”)
    summaries = [{"text": clean_text(r["snippet"]), "source": r["title"]} for r in all_results if r.get("snippet")]
    references = [{"title": clean_text(r["title"]), "url": r["url"]} for r in all_results]
        
    state["external_content"] = {
        "queries": queries,
        "summaries": summaries[:3], # ìƒìœ„ 3ê°œë§Œ ìš”ì•½ì— ì‚¬ìš©
        "references": references[:4] # ìƒìœ„ 4ê°œë§Œ ì°¸ì¡° ì¶œì²˜ë¡œ ì‚¬ìš©
    }
    return state

def node_generate_page_content(state: State) -> State:
    """LLMì„ í˜¸ì¶œí•˜ì—¬ í˜„ì¬ ìŠ¬ë¼ì´ë“œ ì •ë³´ì™€ ì™¸ë¶€ ìë£Œë¥¼ í†µí•©í•˜ì—¬ í˜ì´ì§€ ì„¤ëª…ë¬¸ ìƒì„±"""
    idx        = int(state.get("slide_index", 0))
    titles     = state.get("titles", [])
    texts_all  = state.get("texts", [])
    tables_all = state.get("tables", [])
    images_all = state.get("images", [])
    shapes_all = state.get("shape_texts", [])
    prompt     = clean_text(state.get("prompt", {}).get("style", "")) # style í”„ë¡¬í”„íŠ¸

    title  = clean_text(str(titles[idx])) if idx < len(titles) else ""
    texts  = clean_text(str(texts_all[idx])) if idx < len(texts_all) else ""
    tables = tables_all[idx] if idx < len(tables_all) else []
    images = images_all[idx] if idx < len(images_all) else []
    shapes = shapes_all[idx] if idx < len(shapes_all) else ""

    # í‘œ ì „ì²˜ë¦¬
    table_text = ""
    if tables and tables[0]:
        first_table = tables[0][:6] 
        table_text = "\\n".join([f"| {' | '.join(row)} |" for row in first_table])

    # ì´ë¯¸ì§€ ì¸ì½”ë”© (ìµœëŒ€ 3ì¥)
    image_data_urls = [img_to_data_url(p) for p in images[:3] if os.path.exists(p)]

    # ì™¸ë¶€ ë³´ì™„ ë¸”ë¡ êµ¬ì„±
    ext = state.get("external_content", {}) or {}
    ext_refs      = ext.get("references", [])
    ext_summaries = ext.get("summaries", [])
    
    ext_ref_block = "\\n".join([f"[{i+1}] {r.get('title','')} â€” {r.get('url','')}" for i, r in enumerate(ext_refs)])
    ext_summary_block = "\\n".join([f"- {s.get('text')} ({s.get('source')})" for s in ext_summaries])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    content_input = textwrap.dedent(f"""
        ë‹¤ìŒì€ í•œ ìŠ¬ë¼ì´ë“œì˜ ì •ë³´ì™€ ì™¸ë¶€ ë³´ì™„ ìë£Œì…ë‹ˆë‹¤.
        ì œëª©: {title}
        ---
        [í…ìŠ¤íŠ¸]: {texts}
        [í‘œ]:\\n{table_text}
        [ë„í˜•/ê°ì²´ í…ìŠ¤íŠ¸ ìš”ì•½]: {shapes}
        [í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ ì§€ì¹¨]: {prompt}
        ---
        [ì™¸ë¶€ ë³´ì™„ ìë£Œ]
        - í•µì‹¬ ë³´ê°• ìš”ì•½:\\n{ext_summary_block}
        - ì°¸ì¡° ì¶œì²˜:\\n{ext_ref_block}
        ---
        ê·œì¹™:
        1) ëª¨ë“  ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ **4~6ë¬¸ì¥**ì˜ ê°„ê²°í•œ **ìŠ¬ë¼ì´ë“œ ì„¤ëª…ë¬¸**ì„ ì‘ì„±í•  ê²ƒ.
        2) í‘œ/ì´ë¯¸ì§€/ë„í˜• ì˜ë¯¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•´ ì„¤ëª….
        3) ì™¸ë¶€ ë³´ì™„ ë‚´ìš©ì€ í•µì‹¬ë§Œ ë°˜ì˜í•˜ë©°, ì¶œì²˜ë¥¼ ëŒ€ê´„í˜¸ ìˆ«ìë¡œ í‘œì‹œ (ì˜ˆ: [1][2]).
    """)

    # LLM í˜¸ì¶œ
    messages = [{"role": "system", "content": "ë‹¹ì‹ ì€ ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": [{"type": "text", "text": content_input}]}]
    for img_url in image_data_urls:
        messages[-1]["content"].append({"type": "image_url", "image_url": {"url": img_url}})

    response = client.chat.completions.create(model=LLM_MODEL, messages=messages, temperature=0.5)

    # ê²°ê³¼ ì €ì¥
    page_content = clean_text(response.choices[0].message.content)
    state["page_content"] = " ".join(split_sents(page_content))
    return state

def node_generate_script(state: State) -> State:
    """ê°•ì˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: ì´ì „ ìŠ¤í¬ë¦½íŠ¸ì™€ ë‹¤ìŒ ëª©ì°¨ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ì†ì„± ìˆê²Œ ì‘ì„±"""
    
    all_titles = state.get("titles", [])
    prev_scripts = state.get("all_scripts", [])
    previous_script = prev_scripts[-1] if prev_scripts else "ì—†ìŒ"
    
    prompt_data = state.get("prompt", {})
    tone = prompt_data.get("tone", "ì¹œì ˆí•˜ê³  ëª…ë£Œí•œ ê°•ì˜ í†¤")
    target_time = prompt_data.get("target_duration_sec", 60)
    current_page_content = state.get("page_content", "")

    current_index = state.get("slide_index", 0)
    total_slides = state.get("total_slides", len(all_titles))
    current_title = all_titles[current_index] if all_titles and current_index < len(all_titles) else "í˜„ì¬ ìŠ¬ë¼ì´ë“œ"
    
    # --- ê°•ì˜ íë¦„(Flow) ì§€ì‹œì‚¬í•­ êµ¬ì„± (ê°€ì¥ ì¤‘ìš”í•œ ê³ ë„í™” íŒŒíŠ¸) ---
    flow_instruction = ""
    if current_index == 0:
        flow_instruction = "ì´ê²ƒì€ ì „ì²´ ê°•ì˜ì˜ 'ì²« ë²ˆì§¸' ìŠ¬ë¼ì´ë“œì…ë‹ˆë‹¤. ê°•ì˜ ì „ì²´ë¥¼ ì†Œê°œí•˜ëŠ” 'ë„ì…ë¶€'ë¡œ ì‹œì‘í•˜ë˜, ì²­ì¤‘ì—ê²Œ ì§ì ‘ì ì¸ ì¸ì‚¬ë§ì€ ë„£ì§€ ë§ì•„ ì£¼ì„¸ìš”. í•˜ë‚˜ì˜ ê¸´ ê°•ì˜ê°€ ì‹œì‘ë˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ì „ ë‚´ìš© ìš”ì•½/ë§ˆë¬´ë¦¬ ì¸ì‚¬ëŠ” ê¸ˆì§€)"
    elif current_index == total_slides - 1:
        flow_instruction = "ì´ê²ƒì€ ì „ì²´ ê°•ì˜ì˜ 'ë§ˆì§€ë§‰' ìŠ¬ë¼ì´ë“œì…ë‹ˆë‹¤. ê°•ì˜ ì „ì²´ë¥¼ ìš”ì•½í•˜ê³  ì²­ì¤‘ì—ê²Œ 'ë§ˆë¬´ë¦¬ ëì¸ì‚¬'ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ ì£¼ì„¸ìš”. (ë‹¤ìŒ ë‚´ìš© ì˜ˆê³  ê¸ˆì§€)"
    else:
        next_title = all_titles[current_index + 1] # ë‹¤ìŒ ìŠ¬ë¼ì´ë“œì˜ ì œëª©ì„ ê°€ì ¸ì˜´
        last_sentence_part = previous_script[-50:] if previous_script != "ì—†ìŒ" and len(previous_script) > 50 else previous_script
        
        flow_instruction = (
            f"ì´ê²ƒì€ ê°•ì˜ì˜ 'ì¤‘ê°„' ìŠ¬ë¼ì´ë“œì…ë‹ˆë‹¤. ì§ì „ ìŠ¬ë¼ì´ë“œ ìŠ¤í¬ë¦½íŠ¸ì˜ ë§ˆì§€ë§‰ ë¬¸ì¥(ì˜ˆ: '...{last_sentence_part}')ì—ì„œ ë‚´ìš©ì´ 'ì™„ë²½í•˜ê²Œ ì—°ê²°'ë˜ë„ë¡ í˜„ì¬ ìŠ¬ë¼ì´ë“œì˜ ì„¤ëª…ì„ ë°”ë¡œ ì‹œì‘í•´ ì£¼ì„¸ìš”. "
            f"ìŠ¤í¬ë¦½íŠ¸ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì— ë‹¤ìŒ ìŠ¬ë¼ì´ë“œì˜ ì£¼ì œì¸ '[{next_title}]'ë¥¼ í™œìš©í•˜ì—¬ ì²­ì¤‘ì˜ ê¸°ëŒ€ê°ì„ ë†’ì´ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²° ë° ì˜ˆê³  ë©˜íŠ¸ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. "
            "ë³„ë„ì˜ ì—°ê²° ë©˜íŠ¸ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ì„ ì‹œì‘í•˜ë©°, í•˜ë‚˜ì˜ ê¸´ ê°•ì˜ì²˜ëŸ¼ íë¦„ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ì „ ë‚´ìš© ìš”ì•½ì€ ê¸ˆì§€, ë‹¤ìŒ ë‚´ìš© ì˜ˆê³ ëŠ” í•„ìˆ˜)"
        )

    # --- LLM í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ---
    system_prompt = (
        "ë‹¹ì‹ ì€ ì „ë¬¸ AI ê°•ì‚¬ì…ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì—¬ëŸ¬ ìŠ¬ë¼ì´ë“œë¥¼ ì—°ê²°í•˜ì—¬ ì œì‘ë  'í•˜ë‚˜ì˜ ì—°ì†ì ì¸ ê°•ì˜ ì˜ìƒ'ì— ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤. "
        "ê°•ì˜ì˜ ì „ì²´ ëª©ì°¨ì™€ íë¦„ì„ ê³ ë ¤í•˜ì—¬, ëª¨ë“  ìŠ¬ë¼ì´ë“œ ìŠ¤í¬ë¦½íŠ¸ê°€ ëŠê¹€ ì—†ì´ ë§¤ë„ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
    )

    user_prompt = f"""
    # ì „ì²´ ê°•ì˜ ëª©ì°¨
    {all_titles}

    # í˜„ì¬ ê°•ì˜ ì¤‘ì¸ ìŠ¬ë¼ì´ë“œ
    - ì¸ë±ìŠ¤: {current_index}
    - ì œëª©: {current_title}

    # ì§ì „ ìŠ¬ë¼ì´ë“œ ìŠ¤í¬ë¦½íŠ¸
    {previous_script}

    #í˜„ì¬ ìŠ¬ë¼ì´ë“œ í•µì‹¬ ë‚´ìš©
    {current_page_content}

    # í•„ìˆ˜) ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì¡°ê±´
    1. í†¤ì•¤ë§¤ë„ˆ: {tone}
    2. ë¶„ëŸ‰: ì•½ {target_time}ì´ˆ ë¶„ëŸ‰ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. (TTS ì¬ìƒ ì†ë„ 1.0x ê¸°ì¤€)
    3. [ì¤‘ìš”] íë¦„ ì§€ì‹œì‚¬í•­: {flow_instruction}
    4. [ì—°ì†ì„± ê·œì¹™] 'ì˜¤ëŠ˜', 'ì´ë²ˆ ê°•ì˜ì—ì„œëŠ”', 'ì•ˆë…•í•˜ì„¸ìš”', 'ë§ˆì§€ë§‰ìœ¼ë¡œ', 'ê°ì‚¬í•©ë‹ˆë‹¤' ë“± ê°•ì˜ì˜ ì—°ì†ì„±ì„ ëŠê±°ë‚˜ ì‹œê°„/ë‚ ì§œë¥¼ íŠ¹ì •í•˜ëŠ” í‘œí˜„ì€ ë§ˆì§€ë§‰ ìŠ¬ë¼ì´ë“œì˜ ìµœì¢… ëì¸ì‚¬ë¥¼ ì œì™¸í•˜ê³ ëŠ” **ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
    5. [ìƒë™ê°] ì²­ì¤‘ì˜ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ í˜„ì¬ ìŠ¬ë¼ì´ë“œì˜ ë‚´ìš© ì¤‘ ì¤‘ìš”í•œ ë¶€ë¶„ì´ë‚˜ ê·¸ë˜í”„/ì´ë¯¸ì§€ë¥¼ ì–¸ê¸‰í•˜ë©° 'ì²­ì¤‘ì—ê²Œ ë§ì„ ê±°ëŠ” ë“¯í•œ' êµ¬ì–´ì²´ì™€ ìƒë™ê°ì„ ë¶ˆì–´ ë„£ì–´ì£¼ì„¸ìš”.
    6. [ê·¼ê±° ì œì‹œ] ìŠ¬ë¼ì´ë“œì— ì œì‹œëœ ë°ì´í„°(ê·¸ë˜í”„, í‘œ, ìˆ˜ì¹˜)ë‚˜ ê²€ìƒ‰ëœ ì™¸ë¶€ ì •ë³´(ì˜ˆ: Amazon SageMaker)ë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” "í™”ë©´ì˜ ê·¸ë˜í”„ì—ì„œ", "ì´ í‘œì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆë“¯ì´", "Amazon SageMakerì™€ ê°™ì€ í”Œë«í¼ì„ ì˜ˆë¡œ ë“¤ë©´" ë“±ì˜ í‘œí˜„ìœ¼ë¡œ ê·¼ê±°ë¥¼ ì œì‹œí•˜ë©° ì„¤ëª…í•´ ì£¼ì„¸ìš”.

    [ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘]
    """

    # (3) LLM í˜¸ì¶œ
    response = client.chat.completions.create(
        model=LLM_MODEL, messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], temperature=0.7
    )

    script = clean_text(response.choices[0].message.content).replace("[ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘]", "").replace("[ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ]", "")
    
    # State ì—…ë°ì´íŠ¸
    state["script"] = script
    if "all_scripts" not in state: state["all_scripts"] = []
    state["all_scripts"].append(script)

    return state

def node_tts(state: dict) -> dict:
    """ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìŒì„±(mp3)ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì†ë„ ì¡°ì ˆ"""
    script = state.get("script", "")
    prompt = state.get("prompt", {})
    voice = prompt.get("voice", "alloy").split('-')[-1].strip()
    work_dir = state.get("work_dir", "./")
    speed = float(prompt.get("speed", 1.0))
    slide_idx = int(state.get("slide_index", 0))

    if not script.strip(): raise ValueError("ìŠ¤í¬ë¦½íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    os.makedirs(work_dir, exist_ok=True)
    base_audio_path = os.path.join(work_dir, f"narration_raw_{slide_idx}.mp3")
    final_audio_path = os.path.join(work_dir, f"narration_{slide_idx}_{speed}x.mp3")

    # OpenAI TTS í˜¸ì¶œ
    response = client.audio.speech.create(model=TTS_MODEL, voice=voice, input=script, response_format="mp3")
    with open(base_audio_path, "wb") as f:
        f.write(response.read())

    # FFmpegë¡œ ì†ë„ ì¡°ì ˆ
    if speed != 1.0:
        # ffmpeg atempo í•„í„°ëŠ” 0.5x ~ 100.0xë§Œ ì§€ì› (0.5 ì´í•˜/2.0 ì´ˆê³¼ëŠ” atempo í•„í„° ì²´ì¸ í•„ìš”)
        if speed > 2.0 or speed < 0.5: 
            # 0.5~2.0 ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´, ì—¬ëŸ¬ atempoë¥¼ ì²´ì¸ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì²˜ë¦¬
            current_speed = speed
            atempo_filters = []
            while current_speed > 2.0:
                atempo_filters.append("atempo=2.0")
                current_speed /= 2.0
            while current_speed < 0.5:
                atempo_filters.append("atempo=0.5")
                current_speed /= 0.5
            if current_speed != 1.0:
                 atempo_filters.append(f"atempo={current_speed}")
            filter_chain = ",".join(atempo_filters)
            
        else:
            filter_chain = f"atempo={speed}"

        cmd = ["ffmpeg", "-y", "-i", base_audio_path, "-filter:a", filter_chain, "-b:a", "192k", final_audio_path]
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        
    else:
        final_audio_path = base_audio_path

    state["audio"] = final_audio_path
    
    return state

def node_make_video(state: dict) -> dict:
    """ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ì™€ ìŒì„±ì„ í•©ì³ ìŠ¬ë¼ì´ë“œë³„ MP4 ì˜ìƒ ìƒì„±"""
    slide_imgs = state.get("slide_image", [])
    audio_path = state.get("audio", "")
    work_dir = state.get("work_dir", "./")
    slide_index = state.get("slide_index", 0)

    if not slide_imgs or slide_index >= len(slide_imgs) or not os.path.exists(audio_path):
        return state

    if "video_path" not in state: state["video_path"] = []

    video_filename = f"slide{slide_index+1}_lecture.mp4"
    out_mp4 = os.path.join(work_dir, video_filename)

    # ì‹¤ì œ ì˜ìƒ ìƒì„±
    render_mp4(image_path=slide_imgs[slide_index], audio_path=audio_path, out_mp4=out_mp4)
    
    # ì¤‘ë³µ ë°©ì§€í•˜ì—¬ video_pathì— ì¶”ê°€
    if out_mp4 not in state["video_path"]:
        state["video_path"].append(out_mp4)

    return state

def node_accumulate_and_step(state: dict) -> dict:
    """ì˜ìƒ ëˆ„ì  ë° ë‹¤ìŒ ìŠ¬ë¼ì´ë“œ ì¸ë±ìŠ¤ ì¦ê°€"""
    current_idx = state.get("slide_index", 0)
    total = state.get("total_slides", 1)
    video_list = state.get("video_path", [])

    # ëˆ„ì  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    if "video_paths" not in state or not isinstance(state["video_paths"], list):
        state["video_paths"] = []

    # 1ï¸âƒ£ ì˜ìƒ ê²€ì¦ ë° ëˆ„ì 
    if len(video_list) > current_idx:
        current_video = video_list[current_idx]
        if os.path.exists(current_video):
            if current_video not in state["video_paths"]:
                state["video_paths"].append(current_video)
        else:
            if "failed_slides" not in state: state["failed_slides"] = []
            state["failed_slides"].append(current_idx + 1) # 1-based index
    
    # 2ï¸âƒ£ ë‹¤ìŒ ìŠ¬ë¼ì´ë“œë¡œ ì´ë™
    state["slide_index"] = current_idx + 1

    return state

def router_continue_or_done(state: dict) -> str:
    """ë‹¤ìŒ ìŠ¬ë¼ì´ë“œ ìœ ë¬´ì— ë”°ë¼ CONTINUE ë˜ëŠ” DONE ë¶„ê¸°"""
    current_idx = state.get("slide_index", 0)
    total_slides = state.get("total_slides", len(state.get("titles", [])))

    if current_idx >= total_slides:
        return "done"
    else:
        return "continue"

def node_concat(state: State) -> State:
    """video_pathsì˜ ëª¨ë“  ì˜ìƒì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°í•˜ì—¬ ìµœì¢… ì˜ìƒ ìƒì„±"""
    video_paths = state.get("video_paths", [])
    work_dir = state.get("work_dir", "./step1_output")

    if not video_paths:
        return state

    final_video = os.path.join(work_dir, "final_lecture.mp4")
    
    # FFmpegë¡œ ì˜ìƒ í•©ì¹˜ê¸° (reencode=Falseë¡œ ë¹ ë¥´ê³  ë‹¨ìˆœ ë³µì‚¬)
    concat_videos_ffmpeg(video_paths=video_paths, out_path=final_video, reencode=False)

    state["final_video"] = final_video

    return state

def node_generate_quiz(state: dict) -> dict:
    """ê°•ì˜ ìŠ¤í¬ë¦½íŠ¸ ì „ì²´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³µìŠµ í€´ì¦ˆë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±"""
    all_scripts = state.get("all_scripts", [])

    if not all_scripts:
        state["quiz_set"] = []
        return state

    system_prompt = textwrap.dedent("""
        ë‹¹ì‹ ì€ ê°•ì˜ ë‚´ìš©ì„ ë³µìŠµì‹œí‚¤ëŠ” ì „ë¬¸ êµìœ¡ ë³´ì¡°ì…ë‹ˆë‹¤. ì œê³µëœ ê°•ì˜ ìŠ¤í¬ë¦½íŠ¸ ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ,
        í•µì‹¬ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” í€´ì¦ˆ ì„¸íŠ¸ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
        í€´ì¦ˆëŠ” ë°˜ë“œì‹œ ê°ê´€ì‹ 4ì§€ì„ ë‹¤í˜•ì´ì–´ì•¼ í•˜ë©°, ê°•ì˜ì˜ í•µì‹¬ ê°œë…ì„ ë‹¤ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤.
        **ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.**
    """)

    full_lecture_script = "\\n\\n".join([f"[ìŠ¬ë¼ì´ë“œ {i+1}]\\n{script}" for i, script in enumerate(all_scripts)])

    user_prompt = textwrap.dedent(f"""
        --- [ê°•ì˜ ì „ì²´ ë‚´ìš©] ---
        {full_lecture_script}
        ---

        [ê·œì¹™]
        1. ìœ„ ê°•ì˜ ë‚´ìš© ì „ì²´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì´ 6ê°œì˜ [ê°ê´€ì‹ í€´ì¦ˆ]**ë¥¼ ìƒì„±í•˜ì„¸ìš”.
        2. ê° í€´ì¦ˆëŠ” ë°˜ë“œì‹œ 4ê°œì˜ ì„ íƒì§€(options)ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
        3. **[ì¤‘ìš”]** ê° ì„ íƒì§€ëŠ” **'1. ì„ íƒì§€ ë‚´ìš©', '2. ì„ íƒì§€ ë‚´ìš©'** ì²˜ëŸ¼ ë°˜ë“œì‹œ ë²ˆí˜¸ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
        4. ê° í€´ì¦ˆë§ˆë‹¤ [question], [options], [answer] í‚¤ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
        5. **[ì¤‘ìš”]** ì •ë‹µ(answer)ì€ **ë²ˆí˜¸ê°€ í¬í•¨ëœ ì„ íƒì§€ í…ìŠ¤íŠ¸ì™€ ì •í™•íˆ ì¼ì¹˜**í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: "1. ì„ íƒì§€ 1")
        6. ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

        [JSON ì¶œë ¥]
    """)

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL, messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            response_format={"type": "json_object"}
        )
        quiz_set_data = json.loads(response.choices[0].message.content.strip())
        # LLMì´ ì§ì ‘ ë°°ì—´ì„ ë°˜í™˜í•˜ê±°ë‚˜, "quizzes" ë“±ì˜ í‚¤ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŒ.
        state["quiz_set"] = quiz_set_data.get("quizzes", quiz_set_data) 
    except Exception as e:
        state["quiz_set"] = [] 
        print(f"[ì˜¤ë¥˜] í€´ì¦ˆ ìƒì„± ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
    return state